# -*- coding: utf-8 -*-
"""Model Evaluation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1le-ruVTtOTWq3lALZMSI9PZf0kxvpXwP
"""

import numpy as np
import pandas as pd
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

def get_predictions(models, X_test):
    """Gets predictions from all models including the ensemble."""

    # Random Forest
    y_prob_rf = models['rf'].predict_proba(X_test)[:, 1]

    # Reshape for DL models
    X_test_dl = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))

    # LSTM
    y_prob_lstm = models['lstm'].predict(X_test_dl, verbose=0).flatten()

    # Transformer
    y_prob_trans = models['transformer'].predict(X_test_dl, verbose=0).flatten()

    # Hybrid Ensemble (weighted average of probabilities)
    y_prob_ensemble = (y_prob_rf * 0.4) + (y_prob_lstm * 0.3) + (y_prob_trans * 0.3)

    predictions = {
        "Random Forest": (y_prob_rf > 0.5).astype(int),
        "LSTM": (y_prob_lstm > 0.5).astype(int),
        "Transformer": (y_prob_trans > 0.5).astype(int),
        "Hybrid Ensemble": (y_prob_ensemble > 0.5).astype(int),
    }

    return predictions

def evaluate_models(predictions, y_test):
    """Calculates performance metrics for all models."""
    results = []
    for name, y_pred in predictions.items():
        results.append({
            'Model': name,
            'Accuracy': accuracy_score(y_test, y_pred),
            'Precision': precision_score(y_test, y_pred),
            'Recall': recall_score(y_test, y_pred),
            'F1-Score': f1_score(y_test, y_pred)
        })

    return pd.DataFrame(results)